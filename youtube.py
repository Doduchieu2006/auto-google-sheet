from googleapiclient.discovery import build
from google.oauth2.service_account import Credentials
import gspread
import pandas as pd
from datetime import datetime, timedelta
import unicodedata
import re

# ===============================
# 1. C·∫§U H√åNH
# ===============================
SERVICE_ACCOUNT_FILE = 'service.json'
SCOPES = ['https://www.googleapis.com/auth/spreadsheets']

SPREADSHEET_ID = '1YteY73LkEu2CbNEwWW8ghU5ozEAt28mRrkuLySDzAWk'
SHEET_NAME = 'Youtube'

API_KEY = open('API_keys.txt').read().strip()
CHANNEL_ID = 'UCc_RGAKIULbK6MRvAu47YKQ'
CLASS_NAME = '64HTTT3'

# ===============================
# 2. H√ÄM CHU·∫®N H√ìA
# ===============================
def normalize_text(s: str) -> str:
    if not s:
        return ""
    s = unicodedata.normalize('NFD', s)
    s = ''.join(ch for ch in s if unicodedata.category(ch) != 'Mn')
    s = s.lower()
    s = re.sub(r'[-_/]+', ' ', s)
    s = re.sub(r'[^0-9a-z\s]+', '', s)
    s = re.sub(r'\s+', ' ', s).strip()
    return s


def extract_group_number(group_name: str):
    s = normalize_text(group_name)
    m = re.search(r'nhom\s*(\d+)', s)
    return int(m.group(1)) if m else None


# ===============================
# 3. H√ÄM L·∫§Y LINK THEO L·ªöP + NH√ìM (1‚Äì12)
# ===============================
def get_links_by_class_and_group(videos, class_name, group_from=1, group_to=12):
    """
    B·∫Øt ƒë∆∞·ª£c:
    nhom1, nhom 1, nhom_1, nh√≥m1, NHOM1...
    """
    result = {g: [] for g in range(group_from, group_to + 1)}
    norm_class = normalize_text(class_name)

    for v in videos:
        title_norm = normalize_text(v['title'])

        # ph·∫£i c√≥ t√™n l·ªõp
        if norm_class not in title_norm:
            continue

        for g in range(group_from, group_to + 1):
            # üî• REGEX CHU·∫®N: nhom + optional space + s·ªë
            pattern = rf'nhom\s*{g}\b'
            if re.search(pattern, title_norm):
                result[g].append(v['link'])

    return result



# ===============================
# 4. K·∫æT N·ªêI GOOGLE SHEET
# ===============================
creds = Credentials.from_service_account_file(
    SERVICE_ACCOUNT_FILE, scopes=SCOPES
)
gc = gspread.authorize(creds)
ws = gc.open_by_key(SPREADSHEET_ID).worksheet(SHEET_NAME)

df = pd.DataFrame(ws.get_all_records())
df.columns = df.columns.str.strip()

required_cols = ['Nh√≥m', 'Ti√™u ƒë·ªÅ', 'Link', 'T√¨nh tr·∫°ng']
for c in required_cols:
    if c not in df.columns:
        raise Exception(f"‚ùå Sheet thi·∫øu c·ªôt: {c}")

# ===============================
# 5. L·∫§Y VIDEO 30 NG√ÄY G·∫¶N NH·∫§T
# ===============================
youtube = build('youtube', 'v3', developerKey=API_KEY)
thirty_days_ago = (datetime.utcnow() - timedelta(days=30)).isoformat("T") + "Z"

video_ids = []
next_page = None

while True:
    res = youtube.search().list(
        channelId=CHANNEL_ID,
        part='id',
        order='date',
        publishedAfter=thirty_days_ago,
        type='video',
        maxResults=50,
        pageToken=next_page
    ).execute()

    for item in res['items']:
        video_ids.append(item['id']['videoId'])

    next_page = res.get('nextPageToken')
    if not next_page:
        break

video_ids = list(set(video_ids))

# ===============================
# 6. L·∫§Y TITLE + LINK VIDEO
# ===============================
videos = []

for i in range(0, len(video_ids), 50):
    chunk = video_ids[i:i+50]
    res = youtube.videos().list(
        part='snippet',
        id=','.join(chunk)
    ).execute()

    for v in res['items']:
        videos.append({
            'title': v['snippet']['title'],
            'link': f"https://www.youtube.com/watch?v={v['id']}"
        })

# ===============================
# 7. KI·ªÇM TRA NH√ìM 1‚Äì12 + L·ªöP
# ===============================
links_by_group = get_links_by_class_and_group(
    videos,
    CLASS_NAME,
    group_from=1,
    group_to=12
)

# ===============================
# 8. GHI V√ÄO SHEET (4 C·ªòT)
# ===============================
for i, row in df.iterrows():
    group_name = str(row['Nh√≥m']).strip()
    group_num = extract_group_number(group_name)

    if group_num and group_num in links_by_group and links_by_group[group_num]:
        titles = []
        links = []

        for v in videos:
            if v['link'] in links_by_group[group_num]:
                titles.append(v['title'])
                links.append(v['link'])

        ws.update_cell(i + 2, df.columns.get_loc('Ti√™u ƒë·ªÅ') + 1, '\n'.join(titles))
        ws.update_cell(i + 2, df.columns.get_loc('Link') + 1, '\n'.join(links))
        ws.update_cell(i + 2, df.columns.get_loc('T√¨nh tr·∫°ng') + 1, 'ƒê√£ n·ªôp')

        print(f'‚úÖ Nh√≥m {group_num}: ƒê√£ n·ªôp ({len(links)} video)')
    else:
        ws.update_cell(i + 2, df.columns.get_loc('Ti√™u ƒë·ªÅ') + 1, '')
        ws.update_cell(i + 2, df.columns.get_loc('Link') + 1, '')
        ws.update_cell(i + 2, df.columns.get_loc('T√¨nh tr·∫°ng') + 1, 'Ch∆∞a n·ªôp')

        print(f'‚ùå Nh√≥m {group_num}: Ch∆∞a n·ªôp')

print('üéâ HO√ÄN T·∫§T CHECK YOUTUBE THEO L·ªöP + NH√ìM')
